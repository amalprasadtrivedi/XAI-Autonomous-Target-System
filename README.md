# üéØ XAI-Autonomous-Target-System

> An intelligent, interpretable, and autonomous military-grade object detection system powered by Explainable AI (XAI).

---

## üß† Project Summary

The **XAI-Autonomous-Target-System** is a real-time AI-based military surveillance platform integrating modern object detection models like YOLOv5 and Faster R-CNN with state-of-the-art explainable AI (XAI) tools such as **Grad-CAM**, **LIME**, and **SHAP**.

This system enables **decision transparency** for high-stakes autonomous tasks and supports a **human-in-the-loop** strategy for target validation and trust building.

---

## üóÇÔ∏è Project Structure

```bash
XAI-Autonomous-Target-System/
‚îÇ
‚îú‚îÄ‚îÄ app/                          # üíª Streamlit Frontend UI
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Streamlit App Entry Point
‚îÇ   ‚îú‚îÄ‚îÄ pages/                    # Multi-tab interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_Live_Detection.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2_Explanation_Review.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 3_Operator_Logs.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 4_Analytics_Dashboard.py
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui_helpers.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ display.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ charts.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ config.py
‚îÇ
‚îú‚îÄ‚îÄ backend/                      # üß† ML & Explainability Logic
‚îÇ   ‚îú‚îÄ‚îÄ detection/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ object_detector.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ postprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ xai/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ grad_cam.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lime_explainer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ shap_explainer.py
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ explain_and_detect.py
‚îÇ       ‚îî‚îÄ‚îÄ logger.py
‚îÇ
‚îú‚îÄ‚îÄ models/                       # üì¶ Trained weights
‚îÇ   ‚îú‚îÄ‚îÄ yolo/
‚îÇ   ‚îú‚îÄ‚îÄ faster_rcnn/
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/
‚îÇ
‚îú‚îÄ‚îÄ datasets/                     # üìÇ Datasets and labels
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îú‚îÄ‚îÄ annotations/
‚îÇ   ‚îî‚îÄ‚îÄ samples/
‚îÇ
‚îú‚îÄ‚îÄ evaluation/                   # üìä Evaluation Scripts
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ trust_score.py
‚îÇ   ‚îî‚îÄ‚îÄ error_analysis.py
‚îÇ
‚îú‚îÄ‚îÄ reports/                      # üìë Logs & Research Docs
‚îÇ   ‚îú‚îÄ‚îÄ session_logs.csv
‚îÇ   ‚îú‚îÄ‚îÄ plots/
‚îÇ   ‚îî‚îÄ‚îÄ research_paper_draft.docx
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                    # üß™ Prototypes and Demos
‚îÇ   ‚îú‚îÄ‚îÄ train_model.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ xai_experiments.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ evaluation_report.ipynb
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt              # üì¶ Dependencies
‚îú‚îÄ‚îÄ README.md                     # üìñ Project Documentation
‚îú‚îÄ‚îÄ .env                          # üîê Environment Variables
‚îî‚îÄ‚îÄ setup.sh                      # üîß Setup Script
```

## üöÄ Features

- üõ∞Ô∏è **Real-Time Object Detection**
  - Supports both **YOLOv5** and **Faster R-CNN** models.
  - Detects objects from live video feed, CCTV, or uploaded files.

- üîç **Explainable AI Visualizations**
  - Integrated **Grad-CAM** for heatmap-based visual insights.
  - **LIME** for local interpretable model-agnostic explanations.
  - **SHAP** to show pixel-wise feature attribution.

- üß† **Human-in-the-Loop Decision System**
  - Operators can review AI outputs and accept/reject decisions.
  - Logs feedback for false positives and false negatives.

- üìà **Analytics Dashboard**
  - Displays trust scores, performance metrics, and model accuracy.
  - Visual comparison of human vs. AI decisions.

- üìä **Evaluation Tools**
  - Includes accuracy, F1-score, precision, recall, and mAP.
  - Supports detailed false positive/negative analysis.

- üí¨ **Session Review & Logging**
  - All operator interactions and model outputs are logged.
  - Enables transparency, accountability, and re-trainable feedback loops.

- üîß **Modular Backend Architecture**
  - Clean separation between detection, explanation, and service layers.
  - Easy to plug-and-play different models or explanation engines.

- üì¶ **Model Checkpoints Management**
  - Organize multiple saved weights for different environments.
  - Easy switching between YOLO and R-CNN models via config.

- üß™ **Interactive Notebooks**
  - Jupyter-based prototyping for detection and explainability.
  - Useful for research, experimentation, and model validation.

- üåê **Streamlit Frontend UI**
  - Multi-page, responsive interface for real-time interactions.
  - Operator-friendly design for military and surveillance use cases.


## üñ•Ô∏è Screenshots

| Live Detection | Grad-CAM Overlay | Trust Dashboard |
|----------------|------------------|-----------------|
| ![](https://placehold.co/200x120?text=Live+View) | ![](https://placehold.co/200x120?text=Grad-CAM) | ![](https://placehold.co/200x120?text=Analytics) |

> *(Replace placeholders with actual screenshots in your project repository)*

---

## ‚öôÔ∏è Getting Started

### 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/your-username/XAI-Autonomous-Target-System.git
cd XAI-Autonomous-Target-System
```

## 2Ô∏è‚É£ Install Dependencies
```bash
pip install -r requirements.txt
```

## 3Ô∏è‚É£ Configure Environment
```bash
cp .env.example .env
# Add your custom paths, model checkpoints, or API keys
```

## 4Ô∏è‚É£ Launch the App
```bash
streamlit run app/main.py
```

## üîß Components Overview

### üéØ Object Detection

- `object_detector.py`  
  Handles object detection logic using YOLOv5 or Faster R-CNN models. Accepts image or video frames, returns detected bounding boxes, class labels, and confidence scores.

- `model_loader.py`  
  Loads and initializes pre-trained weights for YOLOv5 or Faster R-CNN. Supports dynamic model switching via configuration.

- `postprocessing.py`  
  Applies filtering, non-maximum suppression (NMS), and visual overlays (boxes, labels, scores) to the detection output.

---

### üí° Explainable AI Modules

- `grad_cam.py`  
  Generates **Grad-CAM** heatmaps for convolutional neural networks. Highlights class-discriminative regions contributing to decisions.

- `lime_explainer.py`  
  Implements **LIME (Local Interpretable Model-agnostic Explanations)**. Explains predictions by perturbing input and training local interpretable models.

- `shap_explainer.py`  
  Uses **SHAP (SHapley Additive exPlanations)** to provide feature importance values. Works with both image and structured data.

---

### üìà Evaluation and Trust Metrics

- `metrics.py`  
  Computes standard evaluation metrics like **accuracy**, **precision**, **recall**, **F1-score**, and **mean Average Precision (mAP)**.

- `trust_score.py`  
  Calculates **trust score** by comparing model predictions with operator decisions. Helps measure AI-human alignment.

- `error_analysis.py`  
  Allows side-by-side visualization of **False Positives (FP)** and **False Negatives (FN)** for performance diagnosis.

---

### üß™ Prototyping and Research

- `train_model.ipynb`  
  Jupyter notebook for training YOLO or Faster R-CNN models on your dataset. Includes data augmentation and checkpoint saving.

- `xai_experiments.ipynb`  
  Compare and visualize outputs from **Grad-CAM**, **LIME**, and **SHAP** on the same sample to analyze interpretability.

- `evaluation_report.ipynb`  
  Generates visual summaries, confusion matrices, and performance plots for internal reporting and presentations.

---

### üåê Frontend (Streamlit UI)

- `main.py`  
  Main Streamlit script to launch the interactive dashboard.

- `pages/1_Live_Detection.py`  
  UI page to run real-time detection using webcam or video file.

- `pages/2_Explanation_Review.py`  
  Shows XAI overlays with options to compare explanations side-by-side.

- `pages/3_Operator_Logs.py`  
  Displays a searchable table of all past session logs and operator feedback.

- `pages/4_Analytics_Dashboard.py`  
  Shows graphs, statistics, trust metrics, and system performance over time.

---

### üß© UI Components & Utilities

- `components/ui_helpers.py`  
  Contains reusable widgets like sliders, toggles, collapsible sections, and card layouts.

- `components/display.py`  
  Displays annotated images, overlays, and detection heatmaps in Streamlit.

- `components/charts.py`  
  Generates matplotlib and seaborn charts for dashboard visuals.

- `utils/config.py`  
  Centralized configuration file containing paths, thresholds, and model settings used across the application.

